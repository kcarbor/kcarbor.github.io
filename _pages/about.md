---
layout: about
title: about
permalink: /
subtitle:  Will AI ruin everything? Probably. I‚Äôm a Philosopher and Computer Scientist asking: But how exactly? And what can we do about it? 

#head of the <a href='https://certain.dfki.de'>Center for European Research in Trusted AI (CERTAIN)</a> and deputy head at the reserach department for <a href='https://www.dfki.de/nmm'>Neuro-Mechanistic Modeling (NMM)</a> at <a href='https://www.dfki.de/web'>German Research Center for Artificial Intelligence (DFKI)</a>. Saarbr√ºcken. Germany. 

profile:
  align: right
  image: prof_pic.jpg
  image_circular: true # crops the image to make it circular
  more_info: >
    <p><a href="https://scholar.google.de/citations?user=v3YfPJIAAAAJ"><i class="fa-brands fa-google-scholar"></i> Google Scholar</a></p> <br>
    <p><a href="https://www.linkedin.com/in/kevin-baum-55999580/"><i class="fa-brands fa-linkedin-in"></i> Linkedin</a></p> <br>


news: false  # includes a list of news items
latest_posts: false  # includes a list of the newest posts
selected_papers: false # includes a list of papers marked as "selected={true}"
social: false  # includes social icons at the bottom of the page
---
<script src="https://kit.fontawesome.com/568534ed70.js" crossorigin="anonymous"></script>


Hi, I'm Kevin Baum, a passionate ethicist (Dr. phil.) and computer scientist (M.Sc.) at the forefront of AI research.
As a senior researcher at the <a href="https://www.dfki.de">German Research Center for Artificial Intelligence (DFKI)</a>, I am dedicated to exploring the myriad challenges arising from the interplay between technology and society, immersing myself in responsible AI theory and practice.

Since October 2024, I have been leading my own research group, <a href="https://dfki.de/en/web/research/research-departments/neuro-mechanistic-modeling/raime">Responsible AI and Machine Ethics (RAIME)</a>. From December 2023 until recently, I headed the <a href="https://certain.dfki.de">Center for European Research in Trusted AI (CERTAIN)</a> and continue to serve on its executive board. Additionally, I am deputy head and lab manager of the <a href="https://www.dfki.de/nmm">Neuro-Mechanistic Modeling (NMM)</a> research department.



**Research Interests:** <br>

üîçü§ñ My interdisciplinary work explores the complex interplay between AI's *perspicuity attributes*‚Äîsuch as transparency and explainability‚Äîand *societal desiderata*, including addressing gaps in responsibility, enabling effective human oversight, and detecting algorithmic unfairness. Beyond my role at DFKI, I engage with these challenges through two major initiatives. I am a member of the [*Transregional Collaborative Research Centre 248* "Foundations of Perspicuous Software Systems" within the Center for Perspicuous Computing (CPEC)](https://www.perspicuous-computing.science/), and I remain closely involved with the interdisciplinary project [*Explainable Intelligent Systems* (EIS)](https://explainable-intelligent.systems/), funded by the Volkswagen Foundation. Additionally, broader questions of hybrid intelligence‚Äîspecifically, how experts can effectively infuse their knowledge (including, but not restricted to moral expertise) into reinforcement learning (RL) systems and derive insights from RL-driven behaviors‚Äîare central to my our project, *Multi-level Abstractions on Causal Modelling for Enhanced Reinforcement Learning* (MAC-MERLin).

üñ•Ô∏èüìä My research takes a philosophically informed approach to topics within computer science, focusing on *algorithmic fairness* and the pursuit of *effective* human oversight. This work builds on methodologies from *explainable artificial intelligence (XAI)* and the emerging field of *mechanistic interpretability*. At its core, this research addresses a broader question: how can normative requirements and technical methods/procedures be meaningfully integrated, a challenge that demands conceptual, normative, and empirical evaluation. Together with my colleagues at [CERTAIN](https://certain.dfki.de), I am particularly interested in exploring how the properties of AI systems commonly grouped under the term *"Trustworthy AI"* can be operationalized and certified, and how these efforts contribute to fostering appropriate trust in AI and cultivating a *healthy trust infrastructure*.

ü§ñüìú My research also delves into *machine ethics*, focusing on integrating moral considerations into AI agents' decision-making frameworks. A key aspect of this work involves embedding *normative reasoning* into reinforcement learning architectures to develop AI agents *sensitive and responsive to normative reasons*. More recently, I have revisited the field of *AI alignment*, exploring ways to ensure AI systems align with human values and ethical principles through means of practical reasoning and justification.

ü§î‚öñÔ∏è My work also extends to the broader field of AI ethics, where, for instance, I contribute to developing ethical guidelines for responsible AI design and deployment. A key focus of my current research is addressing how we should make decisions under normative‚Äîand particularly moral‚Äîuncertainty in both the design and deployment of AI systems. To navigate these challenges, I draw on insights from practical reasoning to facilitate decisions that are as reasonable and defensible as possible. Central to my approach is placing the concept of justifications at the core of application-oriented AI ethics research, emphasizing their importance in fostering accountability and ethical rigor.

üë®‚Äçüè´üìò Besides research, I am deeply involved in *ethical education* for computer science students and professionals, continuously exploring ways to enhance effective teaching methodologies in this area. Notably, our course [*Ethics for Nerds*](https://dcms.cs.uni-saarland.de/ethics_23/) was awarded the ["Hochschulperle des Jahres" by the *German Stifterverband* in 2019](https://saarland-informatics-campus.de/piece-of-news/stifterverband-hochschulperle-des-jahres-2019-fuer-ethics-for-nerds/), a prestigious recognition for innovative approaches in higher education.


**What else I do:** <br>

In addition to my academic and research activities, I have gained practical experience in the *ethical assessment of research projects*. This includes serving as a member and deputy chairman of the [*Commission for the Ethics of Security-Relevant Research* ("Kommission f√ºr die Ethik sicherheitsrelevanter Forschung", KEF)](https://www.uni-saarland.de/verwaltung/wissenschaftliche-integritaet/sicherheitsrelevante-forschung.html) at *Saarland University* (UdS) from 2020 to 2022, as a member of the [*Ethical Review Board* (ERB)](https://erb.cs.uni-saarland.de/) of the *Saarbr√ºcken Informatics Campus* (SIC), and as an [__ethical advisor__](https://www.dfki.de/web/ueber-uns/governance/ethik-team) for the *DFKI Ethics Team* as well as an EU Horizon 2020 project (undisclosed). I am also co-founder of the non-profit association [*Algoright*](https://algoright.de/), an *interdisciplinary think tank* for responsible digitalization, focusing on *science communication* and *ethical consulting*. Additionally, I served as a permanent expert member for digital ethics in the [__Saarland State Parliament's Enquete Commission__ on *Digitalization in Saarland*](https://www.landtag-saar.de/Downloadfile.ashx?FileId=64456&FileName=So16_1902.pdf).  

Beyond these roles, I actively engage in consultancy and keynote speaking, whether in my professional capacity, as a member of *Algoright*, or as a freelancer, sharing insights on topics related to ethics, AI, and digitalization.


**You really want to know more?** <br>

You can find all my publications on [Google Scholar](https://scholar.google.de/citations?user=v3YfPJIAAAAJ&hl=de), [DBLP](https://dblp.org/pid/132/8396.html), and my [PhilPeople](https://philpeople.org/profiles/kevin-baum) profile. For a detailed overview of my academic and professional journey, feel free to browse my [curriculum vitae](/assets/pdf/CV_Baum.pdf).



